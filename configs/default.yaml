# Source configuration
source:
  type: "video"                     # video or camera
  path: "assets/test16-215-275.mp4" # path to video file (for video type)
  camera_id: 0                      # camera device ID (for camera type)

# Display configuration
display:
  enabled: true            # Whether to show tracking visualization window

# Output configuration
output:
  dir: "tracking_results"                # Directory to save tracking artefacts (defaults to experiment output when null)
  save_video: true         # Persist rendered tracking video
  save_txt: true           # Persist MOT-format text results

# Model configuration
model:
  exp_file: "yolox/exps/example/mot/yolox_l_mix_det.py"  # experiment description file
  ckpt: "pretrained/bytetrack_l_mot17.pth.tar"            # checkpoint for eval
  device: "gpu"             # device to run model (cpu or gpu)
  name: "yolox-l"       # YOLOX-large for better accuracy in personal spaces
  fp16: true           # Mixed precision for speed
  fuse: true           # Fuse conv and bn for optimization
  conf: null                # test confidence threshold (null uses experiment default)
  nms: null                 # test NMS threshold (null uses experiment default)
  tsize: null               # test image size (null uses experiment default)
  trt: false                # use TensorRT for inference

# Personal Space Tracking Configuration (Optimized for accuracy)
tracker:
  fps: 30                   # Standard frame rate
  track_high_thresh: 0.4    # Lower threshold to catch all people (critical for safety)
  track_low_thresh: 0.05    # Very low to ensure no missed detections
  new_track_thresh: 0.8     # Higher threshold for new tracks (prevent fragmentation)
  track_buffer: 120         # 4 minutes at 30fps - longer for elderly care scenarios
  match_thresh: 0.6         # Balanced for personal spaces (not too strict, not too loose)
  aspect_ratio_thresh: 2.0  # More lenient for various poses (sitting, lying down)
  min_box_area: 15          # Small enough for distant people in large rooms
  fuse_score: true          # Fuse score and IoU for better association
  # Safety monitoring for reliable tracking
  high_density_threshold: 5        # Lower threshold for homes/offices (5+ people = crowded)
  safety_monitoring: true          # Enable safety monitoring and emergency responses

# Camera Motion Compensation
cmc:
  method: "orb"             # Good for indoor camera movement

# ReID configuration
reid:
  enabled: true                                          # Enable ReID for accurate person tracking
  fast_reid_config: "fast_reid/configs/MOT17/sbs_S50.yml"  # ReID config file path
  fast_reid_weights: "pretrained/mot17_sbs_S50.pth"        # ReID weights file path
  # Appearance matching thresholds (optimized for personal spaces)
  proximity_thresh: 0.3                # Lower IoU requirement (people may be far in large rooms)
  appearance_thresh: 0.3               # Stricter appearance matching (prevent ID switches)
  # ReID triggering (more aggressive for safety)
  reid_ambiguity_thresh: 0.02          # Lower = catch more ambiguous situations
  reid_overlap_thresh: 0.1             # Trigger ReID on slight overlaps (critical for safety)
  reid_min_track_age: 5                # Start ReID quickly (5 frames) for faster stabilization
  reid_early_collect_offset: 2         # Start collecting features even earlier
  # Persistent ReID for long-term person memory
  persistent_max_age_minutes: 1440     # 24 hours - remember people across sessions
  persistent_max_identities: 50        # Personal spaces typically have fewer unique people
  persistent_similarity_threshold: 0.25  # Strict matching for critical applications
